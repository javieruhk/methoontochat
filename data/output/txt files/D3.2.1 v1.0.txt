List of Figures
List of Tables
EXECUTIVE SUMMARY
The present document is the deliverable "D3.2.1 Enriched multilingual ontology with signs in different languages preliminary version" of the EasyTV project, This deliverable gives an overview and documents the EasyTV ontology as of September 2018. The documentation covers, among others, the following topics:• The EasyTV ontology is presented in this deliverable including the description of the current implementation and resources available, and the modelling decisions taken up to the time of writing this document. • The Description of relevant semantic models about linguistic information to be reused in the development of the EasyTV ontology, and the semantic repository data generation including an EasyTV ontology example of use.. • The Description of existing API and tools for natural language processing relevant for the semantic data annotation process (to be carried out by the EasyTV annotation module) that will use for the EasyTV ontology to populate the semantic repository. • The Relationship with other modules of the project where the multilingual ontology is used, more precisely within the crowdsourcing platform. The connection between the EasyTV annotation module with other modules as the Sign Language capturing system is also explained.In addition, the document provides an overview of the methodological guidelines and recommendable infrastructure to be used during the ontology development process as an annex.The deliverable includes some conclusions and future lines of work.INTRODUCTION
The EasyTV crowdsourcing platform relies on ontologies (i.e., semantic data models) that will be exploited in order to annotate Sign Language videos with the aim of easing the translation between videos in different Sign Languages. In computer science, ontologies are defined as "formal, explicit specifications of a shared conceptualization" [16]. The EasyTV ontology will be formal in the sense of following Description Logics and being implemented in the W3C Web Ontology Language standard OWL. The scope of this deliverable is not limited to the description of the resulting ontology. The processes followed and the infrastructure deployed during the ontology development are also explained. In addition, some existing ontologies and natural language processing tools are reviewed as well as the exchange data format to be taken as input of the semantic annotation process.The remainder of this deliverable is structured as follows:• Section 2 provides an introduction to the semantic technologies that are planned to be used within EasyTV crowdsourcing platform in order to link Sign Language videos to ease finding potential translations.• Section 3 provides an overview of the main existing ontologies related to the EasyTV ontology scope. • Section 4 describes the infrastructure deployed during the ontology development process as well as the current implementation of the EasyTV ontology. • Section 5 describes main linguistic libraries and APIs available to be used during the Sign Language video processing and annotation processes. • Section 6 focuses on the video exchange format and the transcription information between the video capturing and the semantic annotation models. • Section 7 provides some conclusions and future lines of work.For the sake of understandability of this document, readers not familiar with the concept of ontologies in computer science and the Web, might find the basis for this topic in the "Ontology Development 101: A Guide to Creating Your First Ontology". SEMANTIC WEB TECHNOLOGIES
The semantic web is an extension of the Web where the meaning (semantics) of the information and services are defined according to agreed data models, also called ontologies. The World Wide Web consortium The volume of semantic data published over the Web has experienced a huge growth in the last decade, mainly boosted by the Linked DataThere is a fundamental question about knowledge base structure when publishing Linked Data. On the one hand developers should define data models (ontology) and, on the other hand, one should create the data (resources) that will be described by means of the ontology, and will be published on the web as Linked Data. To benefit from the semantic web advantages and features, the data annotation and publication should be driven by a validated, correct and robust ontology, developed following methodological guidelines.In computer science, the term ontology is used to refer to a "formal, explicit specification of a shared conceptualization" [16]. Conceptualization refers to an abstract model that allows describing something relevant in the world, for which we normally use concepts, properties and constraints on their application (e.g., the Unified Modelling Language (UML) class diagrams that many software developers use, the entity-relationship models used to organise a database, or any drawing that one makes in a whiteboard to start organising an information model for a system development). All those entities in the abstract model need to be described explicitly aiming at covering as much as possible of the world phenomenon that we are trying to represent. For example, if we are talking about different types of persons or organisations, we should include the different categories of persons and organisations that are involved in our model of the world, as well as the relationships and constraints that hold among them. Being formal refers to the fact that the ontology should be machine-readable (that is, available in some language (e.g., RDF-S or OWL) that can be easily processed). And finally, and most importantly, "shared" reflects the notion that an ontology captures consensual knowledge, that is, it is not private of an individual, but accepted by a group.In the following paragraphs, different technologies used for the development and publication of Linked Data are described. As shown in Figure OWL 8 (Web Ontology Language) is an ontology implementation language designed to represent shared ontologies on the web based on RDF. This language extends the capabilities of other ontology languages as RDF-S by means of incorporating a new vocabulary with attached formal semantics that incorporates inference features. OWL allows creating classes, hierarchies and properties, as well as RDF-S, but also creating local axioms constraints for classes. Such constraints involve existential and universal quantifiers. OWL also provides means to add characteristics to the properties as functional, transitivity, symmetry, etc. SPARQL 9 (SPARQL Protocol and RDF Query Language) is a query language for RDF data established as official recommendation of the W3C. This language allows for mandatory or optional pattern matching in order to query the database. In addition, SPARQL allows for the application of constraints over the queries by stating the graph(s) over which the query should be checked. The results of the SPARQL queries could be a set of values or RDF graphs. In addition to this technologies, in the context of Linked Data some recommendations have been made in order to guide the development and publication of data. First, we should mention the Linked Data principles1. Use URIs 11 as names for things 2. Use HTTP URIs so that people can look up those names. 3. When someone looks up a URI, provide useful information, using the standards (RDF, SPARQL) 4. Include links to other URIs, so that they can discover more things.Finally, apart from the basic linked data publication principles above-mentioned, a 5-star rating schema is provided stablishing best practices for data publication on the web. In particular, these practices emphasize the need not only to publish data using standard technologies, but also to do so in an open fashion. In this way we moved from the idea of linked data the notion of open and linked data (Linked Open Data). The 5-star scheme describes the following levels at which the data should (taken literarily):★ Available on the web (whatever format) but with an open licence, to be Open Data
★★ Available as machine-readable structured data (e.g. excel instead of image scan of a table)
★★★ as ( In summary, this chapter has reviewed the main semantic technologies that will support the extension of the multilingual knowledge base with Sign Language videos described in task T3.2 More precisely, we can state that RDF is the data model to be used to store semantic annotations for Sign Language videos. Such annotations are driven by the EasyTV ontology which is being developed following the OWL ontology implementation language. The RDF containing the annotations will be loaded in a triple store that will provide querying capabilities by means of the SPARQL query language.RELEVANT SEMANTIC MODELS FOR EASYTV
EasyTV crowdsourcing platform aims to facilitate the Sign Language video translation by stablishing links between videos and concepts from a multilingual knowledge base, namely BabelNet. Such links and the navigation through the knowledge base concepts in different language would be exploited to match videos and their potential translations or videos with similar meaning. BabelNet is one of the main resources from the Linguistic Linked Open Data (LLOD) [4] landscape. This LLOD represents an initiative about publishing data for linguistics and natural language processing using the linked data principles presented in Section 2.In the remainder of this section main ontologies and resources to represent linguistic information are presented. More precisely, only those ontologies and models that are reused in the EasyTV ontology are described. For further information about available ontologies that have been developed for representing linguistic information by means of semantic technologies, we suggest interested readers to explore the Linguistic Linked Open Data working group SKOS
The Simple Knowledge Organization System (SKOS) vocabulary is provided as a W3C recommendation from August, 2009, broadly adopted by the semantic web community. This model is designed to link and share knowledge organization systems, being formalized in OWL and defining mainly concept schemas and concepts. The SKOS vocabulary is defined under its URI http://www.w3.org/2004/02/skos/core. Knowledge Organization systems are different types of schemas to organize information in order to ease the knowledge management. These types of schemas include classifications, thesauri, glossaries, dictionaries, etc. In order to contribute to the semantic web and facilitate the translation of these schemas into RDF, the SKOS vocabulary was created. SKOS in an ontology A basic use of SKOS allows identifying conceptual resources (concepts) assigning them URIs, labelling them with literals of one or several languages, documenting them with different types of notes, relating them to each other through informal hierarchical structures or associative networks, and aggregating them to concept schemes. As SKOS in RDF-oriented, it allows the creation and publication of concepts on the web, as well as linking them with data in this same way and even integrate them into other concept schemes.Figure It is important to mention that to represent a KOS system it is necessary to create a URI that uniquely identifies it. For example, when transforming the UNESCO thesaurus, the individual that represents such UNESCO thesaurus would be an instance of the class skos:ConceptSchema. In addition, a URI must be created for each concept collected by the thesaurus at hand, such URIs are defined as instances of the class skos:Concept. By means of the relationship skos:inSchema links are stablished between each of the concepts defined in a KOS system and the system they belong to. In this way, given a concept it can be retrieved the knowledge organization system in which such a concept is defined. In addition, through the relationship skos:hasTopConcept and its inverse skos:topConceptOf, the concepts of the first level of the classification or KOS system are identified.Between different instances of the class skos:Concept serveral relationships could hold as it is shown in Figure Figure 2. SKOS vocabulary overview
As also shown in Figure Lemon
The Lexicon Model for Ontologies (lemon) [10], developed in the framework of the Monnet Between different schemas skos:topConceptOf into account the following challenges (taken literarily from the model website • RDF-native form to enable leverage of existing Semantic Web technologies (SPARQL, OWL, RIF etc.). • Linguistically sound structure based on LMF to enable conversion to existing offline formats.• Separation of the lexicon and ontology layers, to ensure compatibility with existing OWL models. • Linking to data categories, in order to allow for arbitrarily complex linguistic description.• A small model using the principle of least power -the less expressive the language, the more reusable the data.In addition, the lemon model follows a modular approach and it comprises five modules, namely: (1) core module for the representation of grammatical, (basic) morphological and semantic information module;(2) lexical and terminological variation module; (3) phrase structure module; (4) syntactic frames module; and (5) morphological variation module.Figure OntoLex
One of the W3C Ontology Lexicon (OntoLex) community group This work was carried out taking Lexicon Model for Ontologies (lemon) [10] as input to be reviewed, extended and formally modularized by opening it to the community. The resulting model is officially named lemon 18 but also known as OntoLex or lemon-ontolex.OntoLex is divided into five modules, each one implemented in a separate ontology. The core module (URI: http://www.w3.org/ns/lemon/ontolex#) describes lexical entries, their forms and their mapping to the denoted meaning in an ontology. An overview of this module is shown in Figure The rest of the modules are organized as follows:• synsem (URI: http://www.w3.org/ns/lemon/synsem#) is dedicated to represent the syntaxsemantics interface • vartrans (URI: http://www.w3.org/ns/lemon/vartrans#) is used to represent variations and translations • decomp (http://www.w3.org/ns/lemon/decomp#) is oriented to the representation of the internal structure of an entry • lime (http://www.w3.org/ns/lemon/lime#) is designed to represent linguistic metadata  LexInfo
The LexInfo [5] ontology was developed in the context of the Monnet Project. The second version of LexInfo is an extensive ontology of types, values and properties derived partially from ISOcat, and currently its elements capture information from the morphosyntactic, syntactic, syntactic-semantic, semantic and pragmatic levels of linguistic description.  provides access to its service 21 to navigate the semantic network both by API 22 and by a SPARQL endpoint. The RDF data provided through the BabelNet SPARQL endpoint is modelled according to the BabelNet model 24 which is depicted in Figure Following the notion of semantics by reference modelled by lemon, the meanings of the lexical entries are indicated by Babel synsets (represented by skos:Concept) which are linked from the lexical senses (lemon:LexicalSense) by means of the property lemon:reference.BabelNet includes provenance information for senses, for example the Wikipedia Page (bln:wikipediaPage) or, when relevant, the way it was obtained, via automatic translation (bln:byTrans) or thanks to a Wikipedia redirection page (bln:redirection or the source of the entity (dce:source). EASYTV SEMANTIC MODEL PRELIMINAR VERSION
This section describes the ontology development infrastructure set up to support all the activities involved in the ontology development process and the preliminary version of the ontology being developed.Infrastructure for the EasyTV ontology development
In order to support the ontology requirements specification phase, the ontology developers use a Google Spreadsheets to gather and store the functional requirements. This spreadsheet is associated to the EasyTV ontology, published online and openly accessibleAs solution for ontology storage, the EasyTV ontology is stored in a GitHub repository 28 which includes:• A folder with the implementation of the ontology.• A folder with the ontology modelling diagrams.• A folder with the documentation of the ontology. This repository is planned to be used also for issue tracking and gathering ontology releases historical information.The ontology developers may use the GitHub or Git proposed workflow to develop the ontology, which can be summarized in the next steps:1. Create a new branch from the master branch. 2. Add changes to the ontology and commit them. Each commit has to be associated with a commit message, which is a description explaining why a particular change was made. 3. Open a pull request to start a discussion over the changes. 4. If the pull request is approved, merge the new branch into the master branch.The development team uses OnToologyThe structure of the folders generated by OnToology for each ontology contained in the GitHub repository is represented in Figure To support the ontology publication phase, the ontology developers publish the ontology online to be accessible to anyone under its URI. The ontology development team publishes the releases of the ontologies to make the ontology code and its documentation accessible to all the users.To support the maintenance of the ontology, the ontology developers use an issue tracker All the changes and improvements over the ontology need to be agreed by all the ontology development team. The GitHub issue tracker The new requirements which are proposed in a GitHub issue should be added to the ORSD associated to the ontology when the ontology development team approves them. The requirement is considered approved when the ontology developers tag the issue as "requirement" and add a comment associating an identifier and a competency question.Overview of the current EasyTV model development
Ontological requirements
Following the steps proposed in ANEXO I. a first version of the ontological requirements to be fulfilled by the EasyTV ontology have been identified. The Ontology Requirement Specification Document fields are detailed as follows:• Purpose: To describe concepts, relations and attributes to annotate Sign Language videos with linguistic information. The final goal is to link with multilingual semantic resources in order to facilitate translations between annotated videos. • Scope: The scope of the ontology is limited to the linguistic information about the natural language text associated to the videos in which a sign or group of sign is represented. Therefore, the representation of the sign themselves are out of scope.• Ontological requirement:
o Non-Functional requirements: § The ontology should be documented at least in English.§ The ontology should be compatible with the BabelNet model. § The ontology should be implemented in OWL.§ The ontology should be available on-line in different serializations, at least RDF/XML, TTL and HTML. o Functional requirements: the functional requirements for the EasyTV ontology are being gathered in an online spreadsheet which current content is depicted in Figure EasyTV model
During the development of an ontology intended to be published on-line one of the main decision to be taken is the URI design of the ontology and its elements. For the case of the EasyTV ontology a permanent URI has been selected in order to decouple the ontology physical publication from the identifier of the ontology from which it should be recovered online. More precisely, the "w3id" Another important decision is the naming convention to identify ontology elements as classes, object properties, data type properties and instances. In this case the adapted CamelCase in the following way:• Classes and instances identifiers start with capital letter in the first letter for all the words involved in the term. E.g: VideoFrame • Object and datatype properties identifiers start with lowercase for the first word and capital • EasyTV ontology URI: https://w3id.org/def/easytv • example of class URI: https://w3id.org/def/easytv#VideoFrame • example of property URI: https://w3id.org/def/easytv#signForm One of the non-functional requirements defined for this ontology is the need of being aligned with the semantic model used in the multilingual knowledge base BabelNet. In addition, reusing ontological resources is one of the best practices in ontological engineering as it maximizes interoperability between models and data annotated with such models while reducing cost and time during the ontology development. For this reason, a number of models for representing linguistic information by using semantic web technologies have been reused, more precisely, those presented in Section 3 as it can be observed in the "Referenced Ontologies" box in Figure Arrows are used to represent properties between classes and to represent some rdf, rdfs and owl constructs, more precisely: Datatype properties are denoted by rectangles attached to the classes, in an UML-oriented way. Dashed boxes represent datatype properties that can be applied to the class it is attached to while plain boxes represent that the domain of the datatype property is declared to be the class attached.Individuals are denoted by rectangles in which the identifier is underlined.Literals are denoted by rectangles in which the value is included between quotation marks.The representation of additional property axioms (functional, inverse functional, transitive, and symmetric) that are being used in the diagram are shown in the overview ontology legends.In addition, each ontology overview picture includes a legend to remind the reader the graphics meaning.As it can be observed in Figure As a Sign Language expression, which can be a sentence or phrase, might follow a different word order than the written or oral version of the same sentence, two representation of the constructed sentence are needed, namely one for the Sign Language and another one for the corresponding written language version. For example, the sentence "The three elephants" might be represented in Sign Language as the sequence of the sign for "elephant the three". The representation of such are modelled by means of the concepts etv:SingedLinguisticExpression and etv:WrittenLinguisticExpression respectively. Both concepts are subclasses, that is, specialisations, of the etv:LinguisticExpression concept. This new concept has been created as the lemon:LexicalEntry concept cannot be reused for this purpose as the sentences intended to be annotated in the EasyTV crowdsourcing platform do not represent an entry in a lexicon. Lemon has been thought for representing entries that have a particular meaning that could be represented by an ontology concept. Therefore, Lemon does not cover the scope of the EasyTV video annotation task because the wording to be annotated could represent phrases or sentences that do not have a specific sense defined by an ontology concept.It should be mention that lexicons are represented by the class lemon:Lexicon and each lexicon addressed only one language, indicated by the attribute lemon:language. A lexicon is linked to all its lexical entries by means of the relationship lemon:entry.According to the lemon model, the lexical entries can be realised in different ways from a grammatical point of view. More precisely the lemon model states that a form represents one grammatical realization of a lexical entry. This concept is modelled by the class lemon:Form. Individuals of lemon:LexicalEntry are linked to their forms by means of the property lemon:lexicalForm which is further specialized as lemon:canonicalForm , lemon:abstractForm and lemon:otherForm. Each form can have one or more written representations. In order to adapt this modelling to the EasyTV use case the concept lemon:Form has been extended by adding as subclass the concept etv:SignedForm. In this case, lexical entries are linked to etv:SignedForm by means of the property etv:signedForm which is a sub-property of the lemon:lexicalForm. The signs are realized by videos or video frames and it is indicated by means of the property etv:signedRep.The rest of the model has been built by merging the necessary modules from existing ontologies to cover the EasyTV requirements to annotate videos with linguistic information in a way compatible with BabelNet model. For the latter reason (compatibility with BabelNet), the original lemon model has been selected for representing lexical entries and senses rather than its reviewed version, lemon-ontolex. It is worth noting that there are two mechanisms considered in the current model for representing translations. The relation lexinfo:translation (established between senses) which takes into account the sense of the lexical entries being translated and the relation vartrans:translatableAs (established between lexical entries). The lexinfo:translation will be exploited from BabelNet dataset to navigate through senses in different languages while the vartrans:translatableAs would be used, at least in the first iterations, as anchor between lexical entries appearing in the videos being annotated and BabelNet entries.Being able to annotate morphosyntactic information for each form or lexical entry is an important requirement anticipated in this model. Such annotation will help in refining the search for videos for the EasyTV crowdsourcing platform in order to find the most accurate translation. In this sense, it would be needed to annotate at least: the gender, number, person of an entry and whether it is a negation. Having this future use in mind, the concepts lexinfo:MorphosyntacticProperty, lexinfo:Gender, lexinfo:Negative, lexinfo:Number and lexinfo:Person have been reused as well as the corresponding properties lexinfo:morphosyntacticProperty, lexinfo:gender, lexinfo:negative, lexinfo:number and lexinfo:person.   In order to show an example of how the ontology is intended to be used to semantically annotate Sign Language videos provided by the crowdsourcing platform an excerpt of an RDF graph is provided in Figure It should be mentioned that there are ontological requirements defined that should be represented in the ontology and therefore in the data annotations, as for example, the order of the frames within a given video. Sing language videos are segmented in frames with their particular meaning in the sentence or expression (text segment).The ontology enrichment process has to link a sign and its text segment with the suitable class in the ontology that represent the same meaning of the sign. However, the text segment has not enough information in the process to find a suitable match. Information about the syntactic value of the words, their non-derivative form or how the sentence is structured is needed. This information can be retrieved by Natural Language Processing (NLP) tools and libraries for each specific language. The languages involved in the project are Spanish, Italian, Catalan and Greek. Moreover, English has been also included.Requirements
The NLP tools and libraries used for each language should cover the following tasks:Tokenization: Given a character sequence, tokenization is the task of chopping it up into pieces, called tokens. Those tokens represent the minimum unit of information in a document. Tokens are often loosely referred to as words, but they are not always the same. For instance, symbols ("500$"), abbreviations ("he's" or "i.e.,") and specific sequence of characters (plate numbers or IP addresses) can be represented as a unique token or several ones.Lemmatization:
The goal of the lemmatization task is to reduce inflectional forms of a word a word to a common base form, which is typically the one that is represented in dictionaries. For instance, the words "am", "is" and "are" derivative forms of the verb "be". Also, it is used for normalization of words in plural to their singular form (e.g., "hypotheses" to "hypothesis"). In other languages such as Spanish, the lemmatization of words also includes the gender (e.g., "dura (hard)" to "duro (hard)").Part of Speech (POS) tagger:
Given a sentence, determine the category to which a word is assigned in accordance with its syntactic functions (noun, adjective, adverb, verb, etc.). Many words, especially common ones, can serve as multiple parts of speech. For example, "book" can be a noun ("read a book") or verb ("to book a room"). Commonly, libraries include the lemmatization task inside the Part-of-Speech tagger.Named Entity Recognition (NER):
Find each mention of a named entity (Real-world concept denoted with a referent term or proper name) in the text and label its type. Default types are the names of persons, organizations, locations, expressions of times, quantities, monetary values and percentages.Programming language: For the context of the project, the libraries used must be developed in JAVA language or which results can be easily integrated in a JAVA project.NLP Tools and Libraries
Different open NLP tools, libraries and products have been studied in order to fix the requirements explained before for each language. The current state of the art is full of private and public libraries for specific languages and specific purposes. For instance, GitHub contains more than 25K repositories for NLP tasks.The study has been focused over the most common and well-known libraries used in the academia. Finally, four libraries have been selected to cover one or more languages. These libraries will be included in the EasyTV Annotator (see Section 7 to process natural language sentences to contribute in the enrichment process of the ontology. Moreover, an API library has been used to access the data stored in the BabelNet Dataset. The libraries and their characteristics are explained in this section.CoreNLP
Standford CoreNLP [9] is a JAVA library that provides a set of natural language tools. It can give the base forms of words (lemmas), their parts of speech, whether they are names of companies, people, etc., normalize dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases and syntactic dependencies, indicate which noun phrases refer to the same entities, indicate sentiment, extract particular or open-class relations between entity mentions, etc.The library covers languages such as English, Arabic, Chinese, French, German and Spanish. After a study of the library, it has been found that the library will be used only for English in the context of the project, as their models have a very high quality.Stanford CoreNLPIxaPipes
IXApipes [1] is a modular set of Natural Language Processing tools (or pipes 38 ) which provide access to NLP technology for several languages. The IXA pipes architecture concept is oriented as Linux commands in which each of them has a specific task and passes the information to the next through pipes. So processes such as tokenization, part of speech tagging, named entity recognition or sentence parsing are different libraries developed separately, including modules different languages.There are modules for English, Spanish and Basque in each library. Also, there are modules in the part of speech tagging and in the named entity recognition for French, Italian, Galician and German.The tools are developed by the IXA NLP Group of the University of the Basque Country. The libraries are developed in JAVA language by the IXA NLP Group of the University of the Basque Country and are distributed under the Apache License 2.0 (APL 2.0).A preliminary study has found that the part of speech tagger and the lemmatizer (which is included in the part of speech tagger) have better results than CoreNLP for Spanish and Italian. So, this library is used to cover both languages.TreeTagger
TreeTagger [15] is a tool for annotating text with part of speech and lemma information. It was developed in the TC project at the Institute for Computational Linguistics of the University of Stuttgart. Freeling
FreeLing [13] is a C++ library 40 providing language analysis functionalities (morphological analysis, named entity detection, part of speech tagging, parsing, word sense disambiguation, etc.) for a variety of languages including English, Spanish, Catalan and Italian, among others). Also, it includes an API for JAVA.FreeLing is an open source language analysis tool suite released under the Affero GNU General Public License of the Free Software Foundation. FreeLing project was created and maintained at TALP Research Center, in Universitat Politècnica de Catalunya.A preliminary study has shown that this library is the only mature project which covers Catalan language in most of the NLP tasks.BabelNet API
BabelNet offers different APIs 41 to access the data of their graph through HTTP or JAVA. Moreover, there is a SPARQL Endpoint which allows access and query the RDF data of the graph through SPARQL queries. However, both APIs offer an easier interface to search lexical entries, synsets and senses through the graph than SPARQL queries. The API queries offer the possibility to specify features of the word directly, such as the written form, the part of speech tag, the language or its lemmatized word. Thus, the quality of the results of the BabelNet APIs to retrieve the best lexical entry in the graph that represents the word or term in natural language, depend on the information retrieved from the NLP libraries.All the APIs need from a BabelNet API key that it is requested in the web page. The API key provides 1000 Babelcoins per day that represents 1000 queries through any API. It is possible to increase the number of tokens to 50.000 for research purposes. As all the libraries used in the project are in JAVA, the BabelNet JAVA API has been selected.39 http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/ 40 http://nlp.lsi.upc.edu/freeling/index.php/node/1VIDEO, TEXT AND SIGN LANGUAGE REPRESENTATION
For the capturing of Sign Language, we use the EasyTV capturing module, which has been developed in Task 3.1. The module is responsible for acquiring, i.e., capturing and storing, video frame sequences from a depth sensor and extracting information necessary for the construction of motion data, which is used for the realistic avatar playback (in Task 2.4). The capturing process takes place in a room with good lighting conditions and involves a signer speaking Sign Language in front of the depth sensor. Moreover, an admin that controls the capturing software gives instructions to the signer for proper positioning, and marks the start and the end of the capturing process while inspecting the validity of the recordings. The capturing procedure is show below in Figure In order to produce accurate and noiseless motion data, a series of post-processing steps need to be applied after the image acquisition phase. More specifically, in its current development stage, the EasyTV capturing module uses Microsoft Kinect v2.0 sensor to capture high quality RGB and depth sequences. Both types of imaging data are important, with the former (i.e., RGB) being used by the keypoint detection algorithms while the latter (i.e., depth) being necessary for the generation of 3D data. The sequences of the recorded frames are merged into a single video to be used in the annotation phase. The video annotation phase comes after the image acquisition process and concerns the assignment of text (i.e., subtitles) that corresponds to each of the recorded signs and unveils their meaning. In case the recorded video contains more than one signs, the annotation process must occur alongside a video trimming process in which the user breaks up the video into proper segments containing the individual signs.After the completion of the annotation phase, the segmented videos are fed as input into the motion analysis algorithms for the extraction of skeletal data. Skeletal data consist of 3D joints, i.e., keypoints, corresponding to the important visual content of each frame. Due to the nature of Sign Language, we detect 2D keypoints on the hands, face, and body of the signer. Also considering that the detectors currently used in the EasyTV capturing technology are deep networks trained on extracting 2D-keypoints from RGB images, we also need to infer the 3 rd dimension for the motion data, that is, depth. For that reason, an additional processing phase concerns the generation of 3D keypoints by exploiting the depth images captured by the sensor.The final output of the EasyTV capturing module is a set of files containing both 3D motion data and user annotation information for the recorded signs. These files are subsequently uploaded to the crowdsourcing platform (Task 5.2) as a response to a requested task, and then stored into repositories. The RGB videos recorded can also be exported in order to assist the moderator of the platform in the validation step of the crowdsourcing process. All exported files meet the requirements of EasyTV services and modules, such as the multilingual ontology and the realistic 3D avatar. For a more detailed analysis of the EasyTV capturing technology, refer to D3.1.1 "Sign Language capturing technology preliminary version".Before storing the data, the EasyTV crowdsourcing platform has to also obtain annotations given by the multilingual ontology module. These annotations refer to ontology concepts that make it possible to transition from one Sign Language to another. In order to communicate with the multilingual ontology, a communication protocol has to be established. This protocol has to include an invocation procedure and an exchange file format for transferring information. The crowdsourcing platform will invoke a remote procedure or web service and pass a file containing all necessary information as arguments to the multilingual ontology module. Such information might include the whole phrase captured, individual words and video segments corresponding to signs. The multilingual ontology module will respond by returning a file containing the concepts corresponding to the given signs.In this preliminary version of the deliverable, an initial exchange format for the communication with the multilingual ontology is presented(see Figure { "video": { "url": "http://......", "nls": "the tree elephants", "sls": "elephant the three" , "duration": "00:50" , "language": "es" , "segmnents": [ { "order": "1", "start": "00:00", "end" : "00:30", "content" : "elephant" , } { "order": "2", "start": "00:31", "end" : "00:40", "content" : "the" , } { "order": "3", "start": "00:41", "end" : "00:50", "content" : "three" , }] } } EASYTV ANNOTATOR
Introduction
The easyTV Annotator is a JAVA library developed in the context of the EasyTV European project. The purpose of the library is to enrich the multilingual ontology BabelNet with Sign Language information. For this purpose, the library receives from the crowdsourcing platform a Sign Language video with its natural language transcription sentence and its language. The Sign Language video is segmented in pieces of information representing pieces of the natural language transcription sentence. The library processes the natural language sentence identifying its terms and words. Afterwards, the library finds a suitable representation of these terms or words in the multilingual ontology and associates the video frames to such representations. The library uses different natural language libraries for each specific language. Due to the context of the project and the partners involved in this task, the first version of the easyTV-annotator covers: English, Spanish and Greek.The public repo is available in the following link: https://github.com/oeg-upm/easytv-annotatorArchitecture
Figure EasyTV Interface. This module receives the Sign Language information that consists on the sentence and the segmented video and the required language. The module is in charge to manage: the natural language information of the sentence, the video frames, and the information received from the others modules. The module also contains the EasyTV ontology to access and enrich the EasyTV Dataset.NLP Interface. This module groups all the libraries used in the project for NLP tasks for the different languages with a common interface. These included libraries are coreNLP, Ixapipes, Freeling and TreeTagger, presented in Section 5. All these libraries perform the same tasks: they receive a natural language sentence and they do: tokenization, part of speech tagging, lemmatization, and named entity recognition over it. The results are returned to the EasyTV interface module.In order to work with all the different libraries, a new implementation of the concepts Sentence and Token has been created to store the information retrieved from the libraries. The JAVA classes are called ESentence and EToken.BabelNet Interface. This module contains the methods of the JAVA API to access BabelNet Dataset. BabelNet API methods can retrieve synsets of the ontology specifying language, part of speech of the word and the source of the sysnset. Moreover, the method can retrieve the most relevant sense of a synset for a specific language.The BabelNet Interface module tries to find a suitable class in the ontology for each of the words (EToken) that composes the sentence, using the information retrieved by the NLP interface module. The result of the BabelNet Interface module for each word is the BabelNet synset and the preferred BabelNet Sense, both stored in their correspondent EToken.BabelNet Dataset. The BabelNet Dataset is a multilingual encyclopedic dictionary and a semantic network that contains more than 16 millions of multilingual entries stored in RDF triples. BabelNet covers more than 284 languages and integrates information from different sources such as WordNet, Wikipedia or Wikidata. This module does not belong to the easyTV-annotator library. However, it is present in the architecture because it is used through the communication service of the BabelNet API.EasyTV Dataset. This module is the SPARQL endpoint where the results of the easTV-annotator library are stored. Each dataset entry contains the sign language information that will enrich the multilingual ontology BabelNet, storing Babelnet synset identified for each word, its language, its part of speech, and the video frame that involves its representation. Execution
The EasyTV interface module receives a Sign Language video and its language. As Figure Finally, the ETokens that contains a video frame and a synset captured are introduced in the EasyTV dataset. New entries are created according to the proposed model in Section 4 linking the video frame and the BabelNet synset.CONCLUSIONS
Along this document the methodology, infrastructure and current version of the EasyTV ontology have been detailed. A review of existing ontologies for linguistic information and an example about how to use the EasyTV ontology to annotate Sign Language videos have also been provided. The current ontology is based on a core module in which sub-models from SKOS, BabelNet, lemon and LexInfo ontologies are reused.The EasyTV ontology currently published represents an intermediate version that will evolve in the coming months. It covers partially the requirements defined for the model. In addition, the requirements defined for the ontology might evolve according to the crowdsourcing platform development. In this sense, regarding future lines of work, the ontology will be validated according to the needs for the crowdsourcing platforms in terms of annotation of videos and the information needed to retrieve accurate translation of videos (from those annotated in the platform). All the resources produced during the ontology development are available online, and will be updated over time, so they represent the most current view of the ontology to anyone interested.In addition, this deliverable has described different existing technologies from those analysed, to be reused during the project. More precisely, several semantic models for linguistic information have been presented as well as tools for natural language processing.As for the ontology-modelling task, several natural language tools have been analysed to be part of the Sign Language annotator that will enrich the multilingual ontology. Natural language processing tools are run in a previous step before implementing the semantic annotation. They are used for tasks such as tokenization, part of speech tagging, lemmatization and named entity recognition with the transcribed information in natural language received from the Sign Language video. The information retrieved by the tools will help in the ontology enrichment process. The tools analysed for the EasyTV project must cover different languages such as English, Spanish, Italian, Catalan and Greek.Moreover, as BabelNet is the target multilingual ontology that will be enriched with Sign Language information and that represents the base model of the EasyTV ontology, the JAVA API developed by the BabelNet team is used to retrieve suitable classes in the ontology for the words that compose the information. The API has shown that the better results are recovered by lemmatized words in which their part of speech and language is specified. Thus, the quality of the results in this API depends on the results of the NLP tools.As a result, an annotation library named easytv-annotator has been developed to reach the goal of the work package 3.2. The library receives from the word package 3.1 (Sign Language capturing technology) Sign Language information in a specific JSON format, containing the language, the Sign Language video, its frames and the transcribed information in natural language.The library processes the natural language information using the corresponding NLP library to detect tokens, their part of speech, their lemmas and whether there is a named entity. Then, the token words are queried to find a suitable class in BabelNet through the API. Finally, the information of the video frames that compose certain tokens, their information and their BabelNet classes are stored in the EasyTV dataset following the specifications of the EasyTV ontology. In this deliverable, the easyTV-annotator library covers English, Spanish and Greek languages.ANEXO I. METHODOLOGICAL GUIDELINES FOR ONTOLOGY DEVELOPMENT
This section presents the ontology requirements specification, implementation, publication and maintenance processes defined for the EasyTV ontology. The development methodology described in this section has been taken from the European project VICINITY [7] and it is originally based on NeOn methodology [17]. The aim of this section is to define the processes to be carried out during the ontology development. Figure ONTOLOGICAL REQUIREMENTS SPECIFICATION
The aim of the requirements specification process is to state why the ontology is being built and to identify and define the requirements the ontology should fulfil. In this step, involvement and commitment by domain experts is required to generate the appropriate industry perspective and knowledge.The activities proposed for the ontology requirement specification process are shown in Figure Purpose and scope identification
The goal of this activity is to define the purpose and scope of the given ontology or ontology module. The ontology development team works in collaboration with users and domain experts to define the purpose and scope of each ontology or module to be developed.The communication between the domain experts, users and ontology development team could be carried out by means of an online meeting.Data exchange identification
The goal of this activity is for the domain experts to provide to the ontology development team the necessary documentation about the domain to be modelled. The documentation to be shared might correspond to:• Manuals,• APIs specifications,• Datasets,• Standards,• Formats.The communication between the domain experts and the development team could be carried out by means of (online) meetings, email or team communication applications.Ontological requirements proposal
The ontological requirements could be split into: non-functional and functional requirements according to the NeOn Methodology [17]. On the one hand, the non-functional ontological requirements refer to the general requirements or aspects that the ontology should fulfil, including optionally priorities for each requirement. Some examples of this type of requirements are: "the ontology should be implemented in OWL", "The ontology should be documented in English and Spanish", "The ontology should be published on-line following best practices", etc. On the other hand, the functional requirements refer to the content specific requirements the ontology should fulfil.The requirements are often written in the form of Competency Questions [8] and natural language statements, for example "A video can be decomposed in two or more frames".Taking as input the documentation and data provided by domain experts and users, the ontology development team generates a first proposal of ontological requirements written in the form of Competency Questions and natural language statements.The format used for this proposal follows a tabular approach in which the following fields are included:• Requirement identifier, which should be unique for each requirement • Competency question (or natural language statement), which includes: o Question o Answer • Provenance information, which includes:o Origin of the requirement • Partners (users or domain experts) related to the definition of the requirement • Comments about the requirement • Relation with other requirements • Priority of the requirements, which can be high, medium or low • Status of the requirement, which can take the values of "proposed", "accepted", "rejected" or "superseded by" • Sprint where the requirements must be implementedOntological requirements completion and validation
This activity will focus on validating the ontology requirements defined in the previous step. For doing so, domain experts and users in collaboration with the ontology development team would check whether the ontology requirements are correct and complete.The following criteria can be used in this validation task as stated in [8]:• A set of requirements is correct if each requirement refers to some features of the ontology to be developed. • A set of requirements can be considered complete if users and domain experts review the requirements and confirm they are not aware of additional requirements. • A set of requirements can be considered internally consistent if no conflicts exist between the requirements.• A set of requirements is verifiable if there is a finite process with a reasonable cost testing whether the final ontology satisfies each requirement. • Each requirement must be understandable to users and domain experts.• An ontology requirement is unambiguous if it has only one meaning; that is, if it does not suggest any doubt or misunderstanding. • A set of requirements is concise if all requirements are relevant and there are no duplicates.• A set of requirements is realistic if each and every requirement meaning represents a characteristic of the domain.The communication between the domain experts and the development team could be carried out by means of (online) meetings, email or team communication applications.Ontological requirements prioritization
This activity will be performed if there is the need for prioritizing functional requirements. The main implications of this prioritization are the possibility of planning and scheduling the development of the ontology in sprints. This prioritization would be present in the backlog that will drive the ontology development process.To carry out this prioritization the ontology development team works with the domain experts to identify which requirements need to be fulfilled first. The communication between the domain experts and the ontology development team could be carried out by means of an on-line or in-person interview.ORSD formalization
This activity will generate the consolidated document of the requirements. Once the ontology development team has all the information about the requirements, they create the Ontology Requirements Specification Document (ORSD). This specification document stores all the requirements identified and the information associated to them.Ontological requirements formalization
This activity will generate the translation of the ontological requirements, written in natural language, into a formal language, into test cases. These tests cases, which are stored in RDF files, should include:• Identifier of the requirement associated,• Description of the test case, which includes a link to the ORSD,• SPARQL query extracted from the competency question,• Expected result of the query.The goal of this activity is to create machine-readable test cases. These test cases have SPARQL queries which can be executed over the ontology to verify if the ontology satisfies the ontological requirements identified.ONTOLOGY IMPLEMENTATION
The aim of the ontology implementation process is to build the ontology using a formal language, based on the ontological requirements identified by the domain experts. After defining the first set of requirements, though modification and addition of requirements is allowed during the development, the ontology implementation phase is carried out through a number of sprints. The ontology developers schedule and plan the ontology development according to the prioritization of the requirements in the ontology requirements specification process. The ontology development team builds the ontology iteratively, implementing only a certain number of requirements in each iteration. The output of each iteration is a new version of the ontology.Figure Ontology conceptualization
The aim of this activity is to build an ontology model from the ontological requirements identified in the requirements specification process. During the ontology conceptualization, the domain knowledge obtained from the ORSD document is organized and structured into a model by the ontology developers.Encoding
During this activity, the ontology development team generates computable models in the OWL language from the ontology model.The ontology code resultant from this activity includes metadata, such as creator, title, publisher, license and version of the ontology.It is worth noting that during the development of the EasyTV ontology the following Ontology Versioning convention has been adopted:The versioning identification will be as similar as possible to the conventions used in software development. In this case, each release will follow the pattern v.major.minor.fix, where each field follows the rules:• major: The field is updated when the ontology covers the complete domain it intends to model. That is, it is a complete product and covers the final goal of the development.  In each iteration the minor and fix fields might be changed from zero to several times. When developing ontology networks, it could be the case that each module follows its particular version status. For example, one ontology might be in version v1.0.0 while the another ontology of the network might be in version v0.2.3. That is, the network evolution is not managed as a whole, as it is not a particular product but the virtual composition of many ontologies where each ontology evolves independently.Evaluation
Before publishing a release version of the ontology, the developers evaluate the ontology in different aspects:• The ontology developers guarantee that the ontology does not have syntactic, modelling or semantic errors. • The ontology developers guarantee that the ontology fulfil the requirements scheduled for the ontology using the test cases generated in the requirements specification process.ONTOLOGY PUBLICATION
The aim of the ontology publication process is to provide an online ontology accessible both as a human-readable documentation and a machine-readable file from its URI. The ontology needs to be evaluated before its publication to guarantee that is ready to be used. Figure Propose release candidate
Once the ontology developers have implemented and validated the ontology, they propose a release7. 2 . 9 .
Figure 1 .
Figure 2 .
Figure 3 .
Figure 4 .
Figure 5 .
Figure 6 .
Figure 7 .
Figure 8 .
Figure 9 .
Figure 10 .
Figure 11 .
Figure 12 .
Figure 13 :
Figure 14 :
Figure 15 .
Figure 16 .
Figure 17 .
Figure 18 .
Figure 19 .
Figure 20 .
Figure 21 .
Figure 1 .
7
Figure 3 .
Figure 4 .
Figure 5
Figure 5 .
Figure 6 .
Figure 7 .
Figure 8 .
Figure 9 .
Figure 10 .
Figure 11 .
Figure 12 .Task 3 . 2
Figure 13 :
Figure 14 :
Figure 15 .
Figure 16 .
Figure 17 .
Figure 18 .
Figure 19 .
Figure 20 .
o
Figure 21 .
Table of Contents
Table 1 .
ontology prefixes and namespaces ...................................................................... 31Table 1 . Reused ontology prefixes and namespaces
http://easytvproject.eu/https://www.w3.org/TR/owl-ref/http://www.ksl.stanford.edu/people/dlm/papers/ontology101/ontology101-noy-mcguinness.htmlhttps://www.w3.org/http://www.w3.org/2013/data/https://www.w3.org/standards/semanticweb/datahttps://www.w3.org/DesignIssues/LinkedData.htmlhttp://linguistic-lod.orgSKOS -Simple Knowledge Organization System http://www.w3.org/TR/skos-primer/http://bit.ly/easyTVreqshttp://protege.stanford.edu/http://ontoology.linkeddata.es/https://github.com/dgarijo/Widoco/http://oops.linkeddata.es/https://github.com/idafensp/ar2dtoolhttps://github.com/mariapoveda/easytv-onto/issueshttps://stanfordnlp.github.io/CoreNLP/