INTRODUCTION
The Linked Data (LD) effort has become a catalyst for the realization of the vision of the Semantic Web originally proposed by The correct application of ontology development methodologies (e.g., In the last decades a huge amount of research and work on ontology evaluation has been conducted. Some of these attempts define a generic quality evaluation framework As a consequence of the emergence of new methods and techniques, a few tools have been proposed. These tools ease the ontology diagnosis by reducing the human intervention. This is the case of XD-Analyzer 2 , a plug-in for NeOn Toolkit and Ontocheck 3 This paper presents two main contributions. The first contribution consists of a live and on-line catalogue of pitfalls 5 that extends previous works on modeling errors In this paper we first present the catalogue of pitfalls, including a compendium of pitfalls extracted from the literature review and from the manual analysis of ontologies. A classification of such pitfalls according to the Structural, Functional and Usability-Profiling dimensions proposed in COMMON PITFALLS IN ONTOLOGY DEVELOPMENT
One of the most common approaches for evaluating ontologies is to have a checklist of typical errors that other developers have made before. Thus the developer checks the ontology being built against such a list, detects the pitfalls, and corrects them. Our approach does not pretend to create another checklist but to reuse existing works where modeling problems have already been identified and to extend them by incorporating new pitfalls obtained through an empirical evaluation of ontologies already existing.Catalogue of Common Pitfalls
As our long-term goal is to create and maintain a live and on-line pitfall catalogue, we have followed the process sketched in Figure Regarding works on ontology evaluation, we reviewed, reused, and included in the pitfall catalogue outcomes from The catalogue does not pretend to be an exhaustive, rigid and fixed checklist. Besides, in order to keep such a catalogue in continuous evolution we continue working with the manual evaluation of ontologies and aim to discover new pitfalls. We would welcome that OOPS! users and ontology experts propose new pitfalls to introduce them in the catalogue.The current version of the catalogue 8 consists of a list of 40 pitfalls as well as their descriptions. In each pitfall we include provenance information if the pitfall being described was proposed in a previous work. The list includes the following pitfalls:• P01. Creating Polysemous Elements: An ontology element whose name has different meanings is included in the ontology to represent more than one conceptual idea. For example, the class "Theatre" is usedFigure 1. Creation of the pitfall catalogue and maintenance process
to represent both the artistic discipline and the place in which a play is performed. • P02. Creating Synonyms as Classes: Several classes whose identifiers are synonyms are created and defined as equivalent. For example, the classes "Waterfall" and "Cascade" are defined as equivalents. This pitfall is related to the guidelines presented in The contents of some annotation properties are swapped or misused. An example of this type of pitfall is to include in the rdfs:label annotation of the class "Crossroads" the following sentence 'the place of intersection of two or more roads'; and to include in the rdfs:comment annotation the word 'Crossroads'. • P21. Using a Miscellaneous Class: This means creating in a hierarchy a class containing the instances that do not belong to the sibling classes instead of classifying such instances as instances of the class in the upper level of the hierarchy. An example of this type of pitfall is to create the class "HydrographicalResource", and the subclasses "Stream" and "Waterfall", among others, and also the subclass "OtherRiverElement". • P22. Using Different Naming Criteria in the Ontology: Ontology elements are not named following the same convention within the whole ontology. Some notions about naming conventions are provided in • P25. Defining a Relationship Inverse to
Itself: A relationship is defined as inverse of itself. In this case, this property could have been defined as "owl:SymmetricProperty" instead. An example of this type of pitfall is to create the relationship "hasBorderWith" and to state that "hasBorderWith" is its inverse relationship. • P26. Defining Inverse Relationships for a Symmetric One: A relationship is defined as "owl:SymmetricProperty", and such a relationship is defined as inverse of another relationship. For example, to create for the symmetric relationship "farFrom" an inverse relationship, e.g. itself, "farFrom". • P27. Defining Wrong Equivalent Relationships: Two relationships are defined as equivalent relations when they are not necessarily equivalent. An example of this type of pitfalls is to mix up common relationships that could hold between several types of entities, as "hasPart" defined in one ontology between human body parts and the relation "hasPart" defined in another ontology between research plans and research projects. • P28. Defining Wrong Symmetric Relationships: A relationship is defined as symmetric when the relationship is not necessarily symmetric. This situation can appear because the domain and range are too specific; for example, if we define the symmetric relationship "hasSpouse" between the concepts "Man" and "Woman" instead of using the concept "Person" both as domain and range of such a relationship.• P29. Defining Wrong Transitive Relationships: A relationship is defined as transitive when the relationship is not necessarily transitive. An example of this type of pitfall is to create the relationship "participatesIn", whose domain is the union of the concepts "Team" and "Individual" and whose range is the concept "Event", and defining the relationship as transitive. • P30. Missing Equivalent Classes: When an ontology is imported into another, classes with the same conceptual meaning that are duplicated in both ontologies should be defined as equivalent classes in order to benefit the interoperability between both ontologies. However, the ontology developer may miss the definition of equivalent classes in the cases of duplicated concepts. An example of this pitfall is to fail to define the classes 'Trainer' (class in an imported ontology) and 'Coach' (class in the ontology about sports being developed) as equivalent classes. • P31. Defining Wrong Equivalent Classes: Two classes are defined as equivalent when they are not necessarily equivalent. For example, defining "Car" as equivalent to "Vehicle". • P32. Several Classes with the Same Label: Two or more classes have the same content in the rdfs:label annotation. For example, to link the label "Theatre" both with the building and the literary discipline, adding no more labels to them.• P33. Creating a Property Chain with
Just One Property: There is a property chain that includes only one property in the antecedent part. For example, to create the following property chain: isInChargeOf -> supervises.• P34. Untyped Class (Hogan et al., 2010):
A resource is used as a class without having been declared as a Class. An example of this type of pitfall is to create individuals of the class "Person" and to omit that "Person" is a class. Pitfalls Classification
Since the list of pitfalls presented refers to different ontology perspectives, it is advisable to classify them according to some evaluation criteria. Users with an interest in a given aspect of ontology evaluation could easily identify the group of pitfalls in which they might be interested. For this reason, we have classified pitfalls according to the dimensions defined in • Structural Dimension ( Figure Extension with Pitfalls Importance Levels
It is obvious that not all the pitfalls are equally important; their impact in the ontology will depend on multiple factors. For this reason, the pitfall catalogue has been extended with information about how critical the pitfalls are. We have identified three levels:• Critical (1): It is crucial to correct the pitfall. Otherwise, it could affect the ontology consistency, reasoning and applicability, among others. For example, the consequences of "P19. Swapping intersection and union" could lead to logical inconsistences in the ontology, which represents a critical error when reasoning over the populated ontology. • Important (2): Though not critical for ontology function, it is important to correct this type of pitfall. For example, the logical consequences of "P25. Defining a relationship inverse to itself" are the same as if such relationship were defined as symmetric. However, the latter option, that is, using the ontology implementation language constructors for the purpose they were conceived, is a sign of good modeling and understanding of the underlying semantics. • Minor (3): It does not represent a problem.However, correcting it makes the ontology better organized and user friendly. For example, the pitfall "P22. Using different naming criteria in the ontology" is about the appearance of the ontology and does not compromise the proper ontology functioning.These levels do not have clear boundaries in the sense that a particular pitfall in a level could be debatable depending on the modeling styles, ontology requirements, and context of use by an ontology application. For example, in Figure In other cases, how critical a pitfall is depends on the context of use; for example, in a LD development project At the moment of including the importance levels in the catalogue, 35 out of the 40 pitfalls were already defined and published. In order to attach importance levels to the pitfalls, a study was carried out in which the users had to fill in a questionnaire providing the following information:• Level of Confidence: How confident (s)he felt in the ontology evaluation or ontology modeling domains. • Importance Level of Each Pitfall: There was one question per pitfall (from P01 to P35) where the user had to select the importance level of the given pitfall. The possible values were "Critical", "Important" and "Minor" (see above). • Which Pitfalls are Not Important: A list with all the pitfalls was provided and the users were asked to indicate which pitfall would never represent a problem (not pitfalls that could be a problem only in some cases) for them. • Other Comments: A free text box for providing any comment or suggestions.Researchers, mainly experts on ontology modeling or evaluation, within the semantic web community 10 and OOPS! users were invited to fill in the questionnaire. We received 55 responses. We have made the questionnaire available on-line at http://goo.gl/SEddMN in order to allow the community to continue with the assessment of the level of importance of the pitfalls. On the other hand, to assign importance levels to pitfalls according to the data gathered through the survey, we have first assigned weight to each response (3 for critical 11 , 2 for important, and 1 for minor) and to each expertise level (3 for experts, 2 for medium confidence, and 1 for low confidence). For those pitfalls selected as "not important", we have assigned the weight 0 in the corresponding response. The data generated from the survey responses and the ranking calculations are available at the URL: http://goo.gl/0IkbS2Then we have ranked the pitfalls according to the well-known "weighted sum" technique and obtained the ranking shown in the first column from the left in Table Once the pitfalls are ranked, an interval should be defined in order to split the given ranking into 3 parts, one for each importance level. To do this, we have used a method based on the range of the weight values. More precisely, the range (highest weight -lowest weight) is divided into 3. Concretely, the range of the weighted sum ranking is 0.0193 (0.0379 -0.0186). The division of the range among 3 gives us an interval of 0.0064.Finally, the range of the ranking is split into 3, resulting in the following intervals:• Minor: From 0.0186 to 0.0250 (0.0186 + 0.0064) • Important: From 0.0250 to 0.0314 (0.0250 +0.0064) • Critical: From 0.0314 to 0.0379In order to demonstrate that the ranking method selected is robust, we compared it with two other ranking methods, namely, the "lexicographic order" Once the rankings were computed, we analyzed the similitudes and differences between them. That is, given two rankings we measure how similar the orders established for the list of pitfalls are. To do so, we calculated the Kendall coefficient • Weighted Sum -Lexicographic Order: 0.882352941 • Weighted Sum -Centroid Function: 0.905882353 • Lexicographic Order -Centroid Function: 0.929411765We can observe that the three values are very high; this fact means that the rankings are very similar and proves that the decision of choosing the weighted sum does not affect significantly the final classification. In fact, there is only one pitfall, "P24. Using recursive definition" that has been attached to different importance levels according to the weighted sum method (classified as "important") and to the centroid function method (classified as "critical").When a new pitfall is inserted in the catalogue, an importance level has to be assigned to it. This importance level is decided in conjunction with the developers of OOPS!, experienced ontological engineers, and the users (if any) proposing the given pitfall. For the pitfalls P36 to P40, four experts in ontological engineering and vocabulary publication have defined the pitfalls and assigned their importance levels. As a result, the importance levels shown in Table Taking into account the importance levels extracted from the survey and those levels assigned by ontology experts, we have created a final classification of pitfalls as shown in Figure OOPS! (ONTOLOGY PITFALL SCANNER!)
OOPS! is a web-based tool for diagnosing potential problems in ontologies that could lead to modeling errors. This tool is intended to help ontology developers, mainly newcomers, during the ontology validation activity OOPS! Architecture
Figure The user interface consists of a webpage, in which the user enters either the ontology URI or its OWL code, which describes the ontology to be analyzed. Once the ontology is parsed using the Jena API 20 , the "Pitfall Scanner" module inspects the declared ontology 21 looking for pitfalls among those available in the catalogue. More precisely, the 32 pitfalls implemented are those that can be detected (semi-) automatically with the information provided by the ontology OWL code (T-box). Those pitfalls that require an external reference framework (e.g., an ontology requirement document, an A-box or corpora, and/or domain knowledge) or human intervention are not yet automated. During this scanning phase, the ontology elements prone to potential errors are detected, whereas some modeling suggestions are generated by the "Suggestion Scanner" module. Finally, the evaluation results are displayed in the web user interface, which shows the list of pitfalls detected, if any, and the ontology elements affected, as well as explanations describing the findings (Figure Next subsection describes the different approaches used to implement the methods for detecting pitfalls.Pitfall Detection Methods
The pitfall catalogue covers many different aspects of ontologies, such as their internal structure, their associated or embedded humanreadable documentation, or their availability on the Web. As a consequence, the detection methods implemented to detect pitfalls make use of different techniques and technologies for diagnosing them. More precisely, the detection . The patterns can also include statements following the OWL functional syntax, mainly to indicate that the pattern checks the lack of such information. It should be noted that some pitfalls are detected by different patterns, for example, "P19. Swapping intersection and union"; in those cases the pitfall is detected when at least one of the patterns is identified in the ontology. • Lexical Content Analysis: The detection methods based on the analysis of lexical entities make use of the content of annotations (e.g., rdfs:label or rdfs:comment) and identifiers (the ID part of the element URI) for detecting pitfalls. These methods are used in 9 of the 32 implemented pitfalls.For the pitfall "P22. Using different naming criteria in the ontology", the identifiers of the ontology elements are analyzed to check whether all of them use the same naming convection for example, if all the identifiers are formed according to the CamelCase rules. • Specific Characteristic Search: Five detection methods have been automated by checking general characteristics of the ontology not related to the internal structure of the ontology or to the content of the lexical entities. These characteris-tics could be related, for example, to the name given to the ontology as in the pitfall "P36. URI contains file extension", which is detected when the ontology URI refers to the technology or ontology language used during its development as RDF or OWL. Detailed technical information about detection methods for seeking a specific characteristic can be found in Poveda-Villalón et al. ( In addition, some pitfalls can appear several times in the same ontology while others may appear at most once, since they affect the whole ontology instead of its different elements (classes, properties and axioms, among others).Figure There are cases where a detection method uses more than one technique as indicated in Figure It should be noted that for some pitfalls, the detection methods applied might not cover all the possible situations in which a pitfall occurs but a subset of them. In these cases, the methods may be indicators, but for detecting non-simple pitfalls background knowledge might be needed. For example, while "P11. Missing domain or range in properties" is detected in all possible cases by the pattern presented in Figure In other cases, a detected pitfall might not represent a factual error, and this might be due to specific modeling decision or requirements. For example, "P02. Creating synonyms as classes" might be implemented in some cases in order to support backwards compatibility between different versions of the same ontology.MOST COMMON PITFALLS
In order to know which are the most frequent errors in ontology development, we have recorded the number of pitfalls detected in each ontology analyzed with OOPS! To carry out this task we used the 32 pitfalls implemented up to February 2014.When analyzing OOPS! execution logs, we could observe that • Between November 14 th , 2011 and February 17 th , 2014, 1971 executions were carried out. During these executions, the ontology analyzed was identified by its URI in 1809 cases, whereas the ontology was "anonymous" (its URI was not defined or it was "null") in 162 cases. • From these 1809 ontologies identified, some URIs indicate that the same ontology has been evaluated several times. We have filtered duplicated URIs, keeping only the first execution per URI. As a result, we counted 610 different ontologies. Further studies will take into account all the executions per URI and analyze the evolution of the pitfalls appearing. • With regard to the 162 anonymous ontologies, we have removed executions with equal results, assuming that they belong to the same ontology, thus avoiding duplications. As a result, we counted 83 different anonymous ontologies. • Overall, OOPS! has analyzed 693 ontologies 23 (610 with URI and 83 anonymous). This set of random ontologies submitted by OOPS! users contains upper level ontologies, as well as domain ontologies. These ontologies were developed either by domain experts, students, newcomers or ontology experts.Finally, Figure It should be noted that up to September 2013 only 21 were implemented and since then 11 new pitfalls have been implemented and included in the system, more precisely from P30 to P40, marked with a * in Figure This study is complemented with a deeper analysis, described in Keet, Suárez-Figueroa, and Poveda-Villalón (2013), about pitfalls detected in (1) ontologies registered in OOPS! log;(2) ontologies developed by students; and (3) well-known ontologies developed by experts. In this analysis, the authors conclude that in most of the cases there is no clear evidence of noteworthy differences between the ontologies extracted from OOPS! log, the ones developed by students and the well-known ontologies. Therefore, even though the lack or appearance of pitfalls is considered a sign of quality, it could not be considered a measure of maturity in ontologies.USER-BASED EVALUATION
OOPS! main goal is to get ontology evaluation closer to ontology developers, mainly newcomers and domain experts who are not familiar with description logics and ontology implementation languages.In order to have an impression of the users' satisfaction when using OOPS!, a feedback form 24 is available online. On this form users can express their impressions after using the system. The answers to the questionnaire received so far reveal that (a) the tool clearly shows which is the problem detected; (b) OOPS! is a useful system; and (c) users would use it again and recommend it to their colleagues. Some users also pointed out some drawbacks such as (a) only rdfs:label and rdfs:comment are considered as annotation but not skos 25 or dc 26 annotations; and (b) OOPS! does not provide suggestions about how to solve a problem.In that questionnaire, users also indicated how the system effectively improved the ontologies and helped in the process of ontology curation. In this regard, users mainly pointed out that OOPS! was useful for (a) discovering potential missing statements (e.g. human readable annotations, domain and range declarations and property characterization as inverse, among others), (b) detecting incorrect pairs of inverse properties, (c) enriching property definitions (e.g. by adding the symmetric or transitive characteristic). Besides being used to diagnose ontologies, OOPS! has also been useful as part of the ontology assessment process in the context of ontologies for human behavior recognition, as explained in We have also received feedback and suggestions by email in which users show their agreement or disagreement regarding, for example, (a) the pitfall "P13. Missing inverse relationships", which is one of the typical debatable modeling decisions; or (b) when any pitfall detected affects ontology elements that belong to an imported ontology. More detailed information about this type of user evaluation can be found at Next, we present some evidence of how OOPS! has been used and adopted worldwide 27 up to February 17 th , 2014. To do so, we have analyzed the log files from the server (from March 1 st , 2012 to February 17 th , 2014). From these logs we have deduced that OOPS! homepage has been visited over 3000 times from 69 different countries, and that the system has been executed around 2000 times 28 from 48 countries. It should be noted that the total number of dif-ferent IP addresses for accessing and executing OOPS! is 1446 and 535, respectively.Focusing on the ten countries from where OOPS! has been executed most, Figure It is worth mentioning that the OOPS! web service 29 has been integrated by third-party software; more precisely, it has been integrated into the Ontohub repository 30 . Finally, the system has been distributed for local installation within some private enterprises since their security policies do not allow them to submit the ontologies to an external website.RELATED WORK
While in the introduction of this work a number of methods and techniques on ontology evaluation have been reviewed, in this section we focus on existing tools. More precisely, we review topology-based tools for ontology evaluation, that is, those tools focused on the internal Figure There are systems that depend on an associated ontology editor. This is the case of XD-Analyzer 33 , a plug-in for NeOn Toolkit 34 , and Ontocheck 35 Regarding web-based systems, we can consider OQuaRE 37 , which extracts quality measurements from the ontology structure and compares these measurements to certain predefined values. The main drawbacks of this tool are that it does not point out any specific problem and that it does not give any information about how to improve the ontology.Finally, we can mention command-line tools such a Eyeball 38 , which is also available as Java API, a fact that makes its use more suitable for users with technological background. A graphical user interface in the form of a desktop application is also provided; however, the interface is still in an experimental phase. On the other hand, the problems detected by this tool have little overlap with OOPS!. Its main drawbacks are the technical knowledge needed to use it and the installation process required.CONCLUSION AND FUTURE WORK
Evaluating an ontology that is being designed is a vital activity in any ontology development project. A number of approaches for ontology evaluation and tools have been proposed in the literature in the last decades.In this work we have focused on a diagnosis method based on a checklist of common errors against which the ontology is compared. Our first contribution, in the form of a live catalogue of pitfalls, represents an extension of previous works about common problems in ontologies.The automation of the detection process of 32 pitfalls included in the catalogue leads us to our second contribution: OOPS! (OntOlogy Pitfall Scanner!), an online tool for (semi-) automatic ontology diagnosis. This tool aims to help developers, mainly newcomers, during the ontology evaluation activity. OOPS! represents a step forward within ontology evaluation tools since (a) it enlarges the list of errors detected by most recent and available systems, such as MoKi It can be stated that the approach here presented has been widely accepted by the semantic web community and experts in other areas. Our approach is supported by the following facts:  To sum up, it could be stated that the approach proposed in this work has proof of being on the right track since it has become useful for ontology practitioners and for newcomers willing to evaluate their ontologies. All along the paper we have tried to show how both the catalogue and the tool are maintained and evolved according to users' feedback and research results.Even though there are still several complex issues to address, our immediate future work will concentrate on the automation of the remaining 8 pitfalls and the enhancement of some of the already implemented ones. This extension might require increasing the users' interaction with the system by keeping them on the loop and using natural language processing techniques as proposed in Focusing on the LOD scenario in which a huge amount of data is annotated by making use of ontologies, an immediate line of work is to consider such data during the evaluation with the purpose of enhancing the results. As a first step, mismatches between the model defined and the instantiated data could be detected as well as inconsistencies.Another line of work would involve making the system scalable for ontologies that contain a high number of terms. At the moment of writing this paper the system presents important delays with big ontologies, as for example DBpedia ontology 41 , being the main bottleneck the number of object properties defined in the ontologies.More ambitious plans include allowing users to define their own pitfalls or to contextualize existing ones and providing the mechanisms to interpret and process the pitfalls without manual encoding.Finally, the integration of OOPS! within existing ontology editors, such as WebProtege 42 or the NeOn Toolkit, would be very convenient for the users since they would not need to change platforms to repair their ontologies after the diagnosis phase.It should be observed that the term "pitfall" is used all along this paper for characteristics that often represent a problem or that could lead to errors in ontologies; however, this is not always the case. In other words, depending on the ontology at hand, pitfalls can or cannot represent an actual error. The online version of the catalogue is available at http://www.oeg-upm.net/oops/catalogue.jsp. Previous versions were included in The call was launched through several mailing list used by the semantic web community and through particular emails sent to known OOPS! users, mainly experts on ontology modeling or evaluation. 11 It is worth mentioning, since it could seem contradictory, that for processing the data and ranking the pitfalls we have assigned the value 3 for critical pitfalls, so that they appear in the top positions. However, for assigning importance levels within the catalogue we have set the "critical" position in 1, since the critical pitfalls should be corrected in first place.12 See file "SurveyImportanceLevelsLexcico-graphicOrder.pdf" at http://goo.gl/0IkbS2.13
The data and calculations for obtaining the coefficients are available at http://goo.gl/ QeSyHX Asunción Gómez-Pérez is Full Professor at Figure 3 .
Figure 8 .
Figure 9 .
14Figure 3
Missing Basic Information: Some
• P10. Missing Disjointness (Gómez- Pérez, 2004; Noy, & McGuinness, 2001; Rector et al., 2004): The
. Missing Equivalent Properties:
. • P16. Misusing Primitive and Defined Classes (Rector et al., 2004): This pitfall
. Specializing a Hierarchy Exceed- ingly 9 : The
. Specifying the Domain or the Range Exceedingly (Noy, & McGuinness, 2001; Rector et al., 2004): This pitfall
. Swapping Intersection and Union:
• P35. Untyped PropertyGangemi et al., 2006): It
-Profiling Dimension (Gangemi et al., 2006): It
Table 1 .
Table 1 .
Table 2 .
pitfall classification presented in this paper.Table 3 .
International Journal on Semantic Web and Information Systems, 10(2), 7-34, April-June 2014 9International Journal on Semantic Web and Information Systems, 10(2), 7-34, April-June 2014International Journal on Semantic Web and Information Systems, 10(2), 7-34, April-June 2014 15International Journal on Semantic Web and Information Systems, 10(2), 7-34, April-June 2014 19International Journal on Semantic Web and Information Systems, 10(2), 7-34, April-June 2014International Journal on Semantic Web and Information Systems, 10(2), 7-34, April-June 2014 29International Journal on Semantic Web and Information Systems, 10(2), 7-34, April-June 2014